<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <video autoplay="true" id="videoElement">
	
	</video>
    <!-- <img src="images/us.jpg" id="originalImg" /> -->
        <canvas id="reflay" class="overlay" width="100" height="100"></canvas>
    <button id="stop">Stop</button>
    <button id="start">Detect again</button>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="https://unpkg.dev/@vladmandic/face-api/dist/face-api.js"></script>
    <script>
        $(document).ready(async function(){
            var video = document.querySelector("#videoElement");
            const canvas = $('#reflay').get(0);
            video.srcObject = await navigator.mediaDevices.getUserMedia({ video: true });//document.getElementById('originalImg')
            const displaySize = { width: $(video).width(), height: $(video).height() }
            
            async function face(){
                
                const MODEL_URL = 'models'
        
                await faceapi.loadSsdMobilenetv1Model(MODEL_URL)
                await faceapi.loadFaceLandmarkModel(MODEL_URL)
                await faceapi.loadFaceRecognitionModel(MODEL_URL)
                await faceapi.loadFaceExpressionModel(MODEL_URL)
                if (!navigator.mediaDevices.getUserMedia) {
                    console.log(navigator.mediaDevices.getUserMedia);
                   return;
                    
                //     .then(function (stream) {
                //     video.srcObject = stream;
                //     })
                //     .catch(function (err0r) {
                //     console.log("Something went wrong!");
                //     });
                }
                
                faceapi.matchDimensions(canvas, displaySize)

                console.log(video, displaySize);
                var inter = setTimeout(async ()=> {
                    await detectFace(video,displaySize, canvas);
                },200);
                $('#stop').on('click',function(){
                    clearInterval(inter);
                })
            }
            
            face()
            $('#start').on('click', async function(){
                await detectFace(video, displaySize, canvas);
            })
        });
        async function detectFace(video, displaySize, canvas){
            const context = canvas.getContext('2d');

            context.clearRect(0, 0, displaySize.width, displaySize.height);
            let faceDescriptions = await faceapi.detectAllFaces(video).withFaceLandmarks().withFaceDescriptors().withFaceExpressions()
                console.log(faceDescriptions);
                console.log(canvas);
                context.drawImage(video, 0, 0, displaySize.width, displaySize.height);
                faceDescriptions = faceapi.resizeResults(faceDescriptions, displaySize)
                faceapi.draw.drawDetections(canvas, faceDescriptions)
                //faceapi.draw.drawFaceLandmarks(canvas, faceDescriptions)
               // faceapi.draw.drawFaceExpressions(canvas, faceDescriptions)
                
                const labels = ['moiz']

                const labeledFaceDescriptors = await Promise.all(
                    labels.map(async label => {
                        console.log(label)
                        const imgUrl = `images/${label}.jpg`
                        const img = await faceapi.fetchImage(imgUrl)
                        //console.log(img);
                        const faceDescription = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor()
                        
                        if (!faceDescription) {
                        throw new Error(`no faces detected for ${label}`)
                        }
                        
                        const faceDescriptors = [faceDescription.descriptor]
                        return new faceapi.LabeledFaceDescriptors(label, faceDescriptors)
                    })
                );

                const threshold = 0.6
                const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, threshold)

                const results = faceDescriptions.map(fd => faceMatcher.findBestMatch(fd.descriptor))

                results.forEach((bestMatch, i) => {
                    const box = faceDescriptions[i].detection.box
                    const text = bestMatch.toString()

                    const drawBox = new faceapi.draw.DrawBox(box, { label: text })
                    drawBox.draw(canvas)
                })
        }
    </script>
</body>
</html>